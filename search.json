[
  {
    "objectID": "demos_performance.html",
    "href": "demos_performance.html",
    "title": "Example applications and performance",
    "section": "",
    "text": "The following serves as a demonstration/tutorial of how to apply the occupation coding tools on some example data, including full code examples as a tutorial/walkthrough. We also show some tests to compare tool predictions to manually assigned codes in the example data, to serve as basic accuracy tests.\nFurther background to the process and techiques used are set out in these pages. For details on the example data used, see here.\nAll the following examples assume you have a working Python install on your system.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#initial-set-up",
    "href": "demos_performance.html#initial-set-up",
    "title": "Example applications and performance",
    "section": "Initial set up",
    "text": "Initial set up\nTo install occupationcoder-international, you can install the package directly from its Github repository using pip, as set out here. Alternatively, installing the requirements.txt for the present repository will also install everything required.\nWe suggest you create and work from a Python virtual environment (venv) to manage package installs cleanly, but this is not strictly required.\nThe package comes with a “dictionary” for the ISCO-08 coding scheme, so there is no need to set this up manually.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#coding-the-example-data",
    "href": "demos_performance.html#coding-the-example-data",
    "title": "Example applications and performance",
    "section": "Coding the example data",
    "text": "Coding the example data\nWhile occupationcoder-international comes with a script that allows it to be run on an input file directly from the command line, we here demonstrate its use in Python code, as a module. We assume this is the most likely approach for embedding this tool into existing (Python) pipelines.\nTo load the required modules, set up the coder class, and load the example data, you can do the following:\n\nimport pandas as pd\nfrom oc3i import Coder\n\n# Initialise the coder with the desired coding scheme (here ISCO):\ncoder = Coder(scheme = \"isco\")\n\n# Load the example data (please adjust the file path as needed on your machine)\nexample_data = pd.read_csv(\"../data/isco_benchmark_data.csv\", dtype={'MANUAL_ISCO1': str, 'MANUAL_ISCO2': str, 'MANUAL_ISCO3': str})\nexample_data.head()\n\n\n\n\n\n\n\n\nID\nTITLE\nTASKS\nINDUSTRY\nMANUAL_ISCO1\nMANUAL_ISCO2\nMANUAL_ISCO3\nTYPE\nCOMMENTS\n\n\n\n\n0\n1\nKapana seller\ncooking and selling meat\nNaN\n5212\nNaN\nNaN\nSemantic ambiguity\nLocalised term for specific street food seller...\n\n\n1\n2\nPsychologist\nConducting and publishing research into psycho...\nUniversity\n2634\nNaN\nNaN\nScheme ambiguity\nTesting sensitivity of scheme to different typ...\n\n\n2\n3\nPsychologist\nTreating people with mental health conditions\nMedical\n2634\nNaN\nNaN\nScheme ambiguity\nTesting sensitivity of scheme to different typ...\n\n\n3\n4\nClinical psychologist\nTreating people with mental health conditions\nMedical\n2634\nNaN\nNaN\nExact match\nTesting sensitivity of scheme to different typ...\n\n\n4\n5\nfarm help\nodd jobs at farm including fencing and cleaning\nNaN\n921\nNaN\nNaN\nDeeper ambiguity\nTesting detail for \"farm help\". Lack of data f...\n\n\n\n\n\n\n\n\n# Code the example using all text in the TITLE, TASKS and INDUSTRY columns.\nexample_coded = coder.code_data_frame(example_data, \n                                        title_column = \"TITLE\", \n                                        description_column = \"TASKS\", \n                                        sector_column = \"INDUSTRY\")\nexample_coded.head()\n\nCoding 85 records in dataframe...\nWarning: Column 'INDUSTRY' contains 34 missing values. These will be interpreted as empty strings.\nWarning: Column 'TASKS' contains 6 missing values. These will be interpreted as empty strings.\n\n\n\n\n\n\n\n\n\nID\nTITLE\nTASKS\nINDUSTRY\nMANUAL_ISCO1\nMANUAL_ISCO2\nMANUAL_ISCO3\nTYPE\nCOMMENTS\nprediction 1\nprediction 2\nprediction 3\ntitle 1\ntitle 2\ntitle 3\nscore 1\nscore 2\nscore 3\n\n\n\n\n0\n1\nKapana seller\ncooking and selling meat\n\n5212\nNaN\nNaN\nSemantic ambiguity\nLocalised term for specific street food seller...\n3339\n7511\n3434\nBusiness Services Agents Not Elsewhere Classified\nButchers, Fishmongers and Related Food Preparers\nChefs\n44.444444\n33.333333\n33.333333\n\n\n1\n2\nPsychologist\nConducting and publishing research into psycho...\nUniversity\n2634\nNaN\nNaN\nScheme ambiguity\nTesting sensitivity of scheme to different typ...\n2634\n2221\n2230\nPsychologists\nNursing Professionals\nTraditional and Complementary Medicine Profess...\n100.0\n42.857143\n40.0\n\n\n2\n3\nPsychologist\nTreating people with mental health conditions\nMedical\n2634\nNaN\nNaN\nScheme ambiguity\nTesting sensitivity of scheme to different typ...\n3344\n3259\n3252\nMedical Secretaries\nHealth Associate Professionals Not Elsewhere C...\nMedical Records and Health Information Technic...\n51.612903\n38.461538\n28.571429\n\n\n3\n4\nClinical psychologist\nTreating people with mental health conditions\nMedical\n2634\nNaN\nNaN\nExact match\nTesting sensitivity of scheme to different typ...\n2634\n\n\nPsychologists\n\n\n\n\n\n\n\n4\n5\nfarm help\nodd jobs at farm including fencing and cleaning\n\n921\nNaN\nNaN\nDeeper ambiguity\nTesting detail for \"farm help\". Lack of data f...\n9212\n9213\n9211\nLivestock Farm Labourers\nMixed Crop and Livestock Farm Labourers\nCrop Farm Labourers\n61.538462\n61.538462\n61.538462\n\n\n\n\n\n\n\nWe can now assess performance of occupationcoder-international, by calculating “accuracy” as the number of cases where the top predicted code matches the manually assigned code exactly:\n\n# Accuracy 1: number of cases where top prediction matches the preferred manually assigned code:\nmatch1 = (example_coded[\"MANUAL_ISCO1\"] == example_coded[\"prediction 1\"]).sum()\nprint(match1)\n\n42\n\n\nAlternatively, we can be less conservative and also consider cases where either the top 1, 2 or 3 prediction matches the manually assigned code (i.e. assuming a user uses the tool to suggest potential alternative options):\n\n# Accuracy 2: number of cases where manually assigned code is included in the top 3 predictions:\nmatch123 = example_coded[\"MANUAL_ISCO1\"].isin(\n                example_coded[[\"prediction 1\", \"prediction 2\", \"prediction 3\"]].values.flatten()\n           ).sum()\nprint(match123)\n\n66\n\n\nTo avoid needing to re-run the same calculation every time, we can wrap the above in a short function that also calculates the % of the total:\n\ndef matches(dat, preds, output = \"both\"):\n    match1 = (dat[\"MANUAL_ISCO1\"] == dat[preds[0]]).sum()\n\n    match123 = dat[\"MANUAL_ISCO1\"].isin(\n                   dat[preds].values.flatten()\n               ).sum()\n\n    match1p = (match1/len(dat))*100\n    match123p = (match123/len(dat))*100\n    if output == \"both\":\n        return([f\"{match1} ({match1p:.1f}%)\", f\"{match123} ({match123p:.1f}%)\"])\n    if output == \"abs\":\n        return([f\"{match1}\", f\"{match123}\"])\n    if output == \"prop\":\n        return([f\"{match1p:.1f}%\", f\"{match123p:.1f}%\"])\n\nWe can now use this function to calculate performance on different subsets of the data. For example, we first split the full example data set by TYPE (for a more detailed explanation of these data TYPES, see here). Specifically, we split by (1) cases where we expect an exact match; (2) cases that should be codeable but not an exact match; (3) cases we expect to be challenging due to ambiguity:\n\nt1 = example_coded[example_coded[\"TYPE\"] == \"Exact match\"]\nt2 = example_coded[example_coded[\"TYPE\"].isna()]\nt3 = example_coded[example_coded[\"TYPE\"].str.contains('ambigui', case=False, na=False)]",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#accuracy-performance",
    "href": "demos_performance.html#accuracy-performance",
    "title": "Example applications and performance",
    "section": "Accuracy & performance",
    "text": "Accuracy & performance\nNow we can use our function above on the full example data set, as well as the subsets, and collate a summary table (note that the code below does not follow best practice; this is deliberate to ensure maximum accessibility):\n\npreds1 = [\"prediction 1\", \"prediction 2\", \"prediction 3\"]\nsummary1 = [\n    [\"All examples\", len(example_coded),matches(example_coded, preds1)[0],matches(example_coded, preds1)[1]],\n    [\"Expected exact match\", len(t1), matches(t1, preds1)[0],matches(t1, preds1)[1]],\n    [\"Expected codeable\", len(t2), matches(t2, preds1)[0],matches(t2, preds1)[1]],\n    [\"Expected ambiguity\", len(t3), matches(t3, preds1)[0],matches(t3, preds1)[1]]\n]\npd.DataFrame(summary1, columns = [\"Type\",\"Total\", \"Match to 1\",\"Match in 1-3\",])\n\n\n\n\n\n\n\n\nType\nTotal\nMatch to 1\nMatch in 1-3\n\n\n\n\n0\nAll examples\n85\n42 (49.4%)\n66 (77.6%)\n\n\n1\nExpected exact match\n17\n17 (100.0%)\n17 (100.0%)\n\n\n2\nExpected codeable\n40\n17 (42.5%)\n30 (75.0%)\n\n\n3\nExpected ambiguity\n25\n6 (24.0%)\n14 (56.0%)\n\n\n\n\n\n\n\nThe above results show that:\n\nWhen considering all of the example data in 49.4% of cases, the top prediction from occupationcoder-international agrees with a manually assigned code. When interpreting a “match” as the manual code being included in the top 3 predictions, this increases to 77.6% cases. It is worth stressing this includes all example cases we a priori expected to be challenging.\n\nAs expected, direct match rates are much lower for known ambiguous cases (24.0%); but this is much improved by also considering the top 3 predictions (56.0%).\nLess informative (as this is a feature of occupationcoder-international, but nevertheless a good sense check), in all cases where we expected an exact match, this is matched correctly.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#initial-set-up-1",
    "href": "demos_performance.html#initial-set-up-1",
    "title": "Example applications and performance",
    "section": "Initial set up",
    "text": "Initial set up\nClassifai can be installed either by following the instructions provided with its repository (recommended method); or as of the time of writing this, by installing the requirements for the present repository (noting that this may change as classifai is under active development).\nNote the following key points:\n\nFor the purposes of this demonstration, we are using a pretrained model from Huggingface as the vectoriser for schema and input text. As this involves downloading a model from the Huggingface website, this assumes you have an appropriate API key set up and referenced in the machine you are using. If this is not done, the following code will fail to run.\n\nClassifai provides ways to use range of different models (and different model providers) as vectorisers - please see its documentation on how to use these.\nDifferent models will vary in terms of performance. For the purposes of the initial demonstration here, we only use one; the main idea being the comparison of its performance on benchmark data with the peformance of other tools such as occupationcoder-international. Further work comparing different vectoriser models used by Classifai would be valuable.\nThe vectorisation of the coding scheme demonstrated below can take a while to run, depending on the hardware used. We suggest that you do this once, store the vector database locally, and when you need to re-use it, you load the stored version rather than re-building in each time. This is a key way to make the coding as efficient as possible, and each “query” should only take milliseconds to complete, even on modest hardware.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#processing-scheme-and-input-data",
    "href": "demos_performance.html#processing-scheme-and-input-data",
    "title": "Example applications and performance",
    "section": "Processing scheme and input data",
    "text": "Processing scheme and input data\nWe first need to retrieve the raw ISCO coding scheme data, and then convert this into a format that can be easily vectorised by the tools included in classifai.\nTo do this, we first set some variables that (1) specify the location of the raw ISCO scheme data, (2) the location where we want to save this, and (3) what we want to name the processed data file. Note that the ISCO-08 scheme can be downloaded from the ILO website; a copy is also included with the occupationcoder-international repository - we here source from the latter.\n\nISCO_DATA_SOURCE = \"https://raw.githubusercontent.com/datasciencecampus/occupationcoder-international/main/data/ISCO-08%20EN%20Structure%20and%20definitions.xlsx\"\nISCO_DATA_FILE = \"../data/ISCO-08-scheme.xlsx\" # Please adjust this path as required if running this code on your machine\nPROCESSED_ISCO_DATA = \"../data/ISCO-08-processed.csv\" # Please adjust this path as required if running this code on your machine\n\nWe can now download and save the ISCO file using a simple helper function included with this repository:\n\nimport os, sys\nsys.path.append(os.path.abspath(\"..\"))\nfrom src.utils import get_isco_scheme_data\nif not os.path.exists(ISCO_DATA_FILE):\n    get_isco_scheme_data(source_url=ISCO_DATA_SOURCE, local_file_path=ISCO_DATA_FILE)\n\nAs described in more detail here, the ISCO-08 scheme consists of separate columns containing the ISCO code, the corresponding title, and various description fields. We here chose to simply concatenate the latter, resulting in a raw input file with two columns: ISCO code, and all description for that code. For the sake of simplicity, we provide a helper function that does this; used as follows:\n\nfrom src.utils import process_excel_to_csv\nprocess_excel_to_csv(ISCO_DATA_FILE, PROCESSED_ISCO_DATA)\n\nFiltered and processed data saved to ../data/ISCO-08-processed.csv",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#creating-the-vector-store",
    "href": "demos_performance.html#creating-the-vector-store",
    "title": "Example applications and performance",
    "section": "Creating the vector store",
    "text": "Creating the vector store\nNow that we have the scheme data processed in a format that can be used easily by Classifai, we download our chosen model for this example () from Huggingface. Note the point above re ensuring you have a suitable API key set up in your system.\n\nfrom classifai.vectorisers import HuggingFaceVectoriser\nfrom classifai.indexers import VectorStore\nhf_vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/classifai/indexers/main.py:38: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can now use this model and the Classifai functions to create a local vector database from the scheme data. As above, we only need to do this once on a given machine - so the code below first checks whether we already have a previously created store, and loads this if available. Otherwise, it creates a new one.\n\nif not os.path.exists(\"../data/hf_vectoriser\"):\n    hf_vector_store = VectorStore(\n        file_name=\"../data/ISCO-08-processed.csv\",\n        data_type=\"csv\",\n        vectoriser=hf_vectoriser,\n        output_dir=\"../data/hf_vectoriser\",\n        overwrite=True\n    )\nelse:\n    hf_vector_store = VectorStore.from_filespace(folder_path=\"../data/hf_vectoriser\",vectoriser=hf_vectoriser)\n\nINFO - Processing file: ../data/ISCO-08-processed.csv...\n\n\n\n\n\n\nINFO - Gathering metadata and saving vector store / metadata...\nINFO - Vector Store created - files saved to ../data/hf_vectoriser",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#coding-the-example-data-1",
    "href": "demos_performance.html#coding-the-example-data-1",
    "title": "Example applications and performance",
    "section": "Coding the example data",
    "text": "Coding the example data\nNow that we have the local vector database from the scheme, we can use Classifai to code the example data. For the purposes of this example, we simply extract all available input text (ie job title, tasks description and industry description) from the example data, and combine this into a single string.\n\njobs = example_coded[\"TITLE\"] + \" \" + example_coded[\"TASKS\"] + \" \" + example_coded[\"INDUSTRY\"]\nclassifai_coded = hf_vector_store.search(jobs.tolist(), n_results=3)\n\n\n\n\nClassifai outputs results in a longitudinal format where “rank” 0-2 indicates the first, second and third best match respectively. For convenience, we here extract each of these in turn for a given example, and add these as coluns to our example coded data set.\n\nexample_coded[\"classifai_p0\"] = classifai_coded[classifai_coded[\"rank\"]==0][\"doc_id\"].values\nexample_coded[\"classifai_p1\"] = classifai_coded[classifai_coded[\"rank\"]==1][\"doc_id\"].values\nexample_coded[\"classifai_p2\"] = classifai_coded[classifai_coded[\"rank\"]==2][\"doc_id\"].values",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#accuracy-performance-1",
    "href": "demos_performance.html#accuracy-performance-1",
    "title": "Example applications and performance",
    "section": "Accuracy & performance",
    "text": "Accuracy & performance\nWe can now compare the manually assigned code to the ones top 3 matches provided by Classifai, following the same approach as for occupationcoder-international as above. We first extract subsets of the data for expected exact matches, expected codeable, and expected ambiguous examples:\n\nt1a = example_coded[example_coded[\"TYPE\"] == \"Exact match\"]\nt2a = example_coded[example_coded[\"TYPE\"].isna()]\nt3a = example_coded[example_coded[\"TYPE\"].str.contains('ambigui', case=False, na=False)]\n\nWe then use the same macthing function defined above - but this time using the Classifai predictions.\n\npreds2 = [\"classifai_p0\", \"classifai_p1\", \"classifai_p2\"]\nsummary2 = [\n    [\"All examples\", len(example_coded),matches(example_coded, preds2)[0], matches(example_coded, preds2)[1]],\n    [\"Expected exact match\", len(t1a), matches(t1a, preds2)[0],matches(t1a, preds2)[1]],\n    [\"Expected codeable\", len(t2a), matches(t2a, preds2)[0],matches(t2a,preds2)[1]],\n    [\"Expected ambiguity\", len(t3a), matches(t3a, preds2)[0],matches(t3a, preds2)[1]]\n]\npd.DataFrame(summary2, columns = [\"Type\",\"Total\", \"Match to 1\",\"Match in 1-3\",])\n\n\n\n\n\n\n\n\nType\nTotal\nMatch to 1\nMatch in 1-3\n\n\n\n\n0\nAll examples\n85\n47 (55.3%)\n75 (88.2%)\n\n\n1\nExpected exact match\n17\n13 (76.5%)\n16 (94.1%)\n\n\n2\nExpected codeable\n40\n23 (57.5%)\n37 (92.5%)\n\n\n3\nExpected ambiguity\n25\n10 (40.0%)\n16 (64.0%)\n\n\n\n\n\n\n\n\nAcross all of the example data in 55.3% of cases, the top prediction from Classifai agrees with a manually assigned code. When interpreting a “match” as the manual code being included in the top 3 predictions, this increases to 88.2% cases. It is worth stressing this includes all example cases we a priori expected to be challenging.\n\nMatch rates to the top predictions are lower for known ambiguous cases (40.0%); but this is much improved by also considering the top 3 predictions (64.0%).",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "With this repository, we aim to provide a demonstration of:",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#what-is-occupation-coding",
    "href": "index.html#what-is-occupation-coding",
    "title": "Introduction",
    "section": "What is “occupation coding”",
    "text": "What is “occupation coding”\nData on respondents’ occupations are typically collected by National Statistics Organisations (NSOs) in a variety of surveys, including e.g. national Labour Force Surveys or Censuses. In such surveys, enumerators or field workers record the answers to questions like “How would you describe the job you have done in the last X months” and “What tasks did this job involve”. The answer to these questions is typically recorded as short text strings (often not more than a few words).\nOn the basis of these text inputs, either the same enumerators, or clerical coders following receipt of the data, are expected to assign at least one suitable class from a coding scheme (e.g. ISCO-08) which best fits the given description. Such coding schemes are set up to link job descriptions to a range of standardised classes, each with a numeric code. Such schemes allow for consistent statistical reporting, and provide a means of international comparability. ISCO-08 is the international standard for this, but many countries use bespoke coding schemes that are partly or wholly based on ISCO (for example, the UK uses a national scheme called SOC, whereas the Namibian scheme is referred to as NASCO).\nWithout going into detail, such coding schemes consist of numerical classes (codes), with a short title (e.g. “Psychologists”) and usually a description that details the sort of tasks typically performed, associated typical industries or sectors, and often a list of specific job titles associated with that class and/or ones that should be explicitly coded to something else. These coding schemes are usually hierarchical: i.e. “secondary school teachers” are part of a wider group of “teachers”, which in turn might be grouped into “educational workers”; the level in the hierarchy is typically reflected in the number of digits of the associated code.\nDepending on the agreed process, if the text description is ambiguous relative to the coding scheme, more than one candidate code might be assigned, or coding might revert to a higher level in the hierarchy.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#common-challenges",
    "href": "index.html#common-challenges",
    "title": "Introduction",
    "section": "Common challenges",
    "text": "Common challenges\nTraditionally, appropriate classification of job descriptions to codes/classes relies on correct application of the coding scheme by enumerators or clerical coders; both in terms of their knowledge of its content and coverage, as well as its limitations.\nThis heavily relies on training and maintenance of skills, and while not a trivial task, this is often underresourced. This can lead to data quality challenges. For example, it is vital that field enumerators ask follow up questions if initial answers are too limited in detail to allow accurate coding to a class in the scheme. Similarly, if coding is done by clerical coders when data has already been collected, it is important for them to have a solid understanding of the limitations of the data, the scheme, and the end use of the data set to allow appropriate coding given the data available. This often involves trade-offs, selection of multiple potentially suitable candidate codes, and ensuring consistent processes are followed.\nConistency is key, but also the main challenge.\nIn many cases, even when appropriately trained, different coders may code inputs differently when they are ambiguous or when the scheme is lacking in detail.\nThus, in an ideal world, extensive validation takes place. This can mean multiple clerical coders coding the same subsets of data in a “double blind” fashion, and revising cases where different coders have given different answers. However, this can be extremely resource intensive in many real-world scenarios where surveys (e.g. national censuses) consist of many millions of records.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#purpose-of-coding-tools-in-general",
    "href": "index.html#purpose-of-coding-tools-in-general",
    "title": "Introduction",
    "section": "Purpose of coding tools in general",
    "text": "Purpose of coding tools in general\nOccupation coding tools aim to reduce the workload involved in coding records: in particular in the context of validation checks.\nIt is worth stressing that here, we argue that such tools should always be viewed as “coding-assist tools”, as opposed to “automatic coders”. From the discussion presented throughout these pages it should be clear that (given limited input data) much of the ambiguity faced by human coders remains just as ambiguous to pretty much any coding tool. Put another way, typically the main challenge is limitations in the input data and granularity of the coding schemes, not the quality of the coding process itself (whether done by a human or otherwise). Some automation tools will struggle more than others, and keeping a “human in the loop” is vital to ensure data quality, particularly where the end product is business critical.\nOur assumption with all of the process and analyses presented here is that these tools will be used when manually assigned codes are already available, and they are used to check and potentially revise assigned codes, based on alternatives presented. While it would be technically possible to embed these coding tools in commonly used data collection tools (e.g. CSPro), we here focus on their role in data processing rather than collection.\nFrom a data processing perspective, the obvious stage to apply these tools is during the data validation process - that is, identifying subsets of records that (1) do not need further intervention: i.e. the tool prediction concurs with the manual code; (2) mismatches between tool predictions and manual code that may need brief review; and (3) cases where there is no agreement at all between tool predictions and manual codes: these need manual intervention.\nThe objective is to maximise the number of cases in the first group, thereby increasing data validation efficiency.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#occupationcoder-international",
    "href": "index.html#occupationcoder-international",
    "title": "Introduction",
    "section": "occupationcoder-international",
    "text": "occupationcoder-international\noccupationcoder-international is a string “fuzzy matching” tool, extending an existing tool for the UK SOC scheme to the international ISCO one.\nIn brief, occupationcoder-international compares a given text input to each of the class descriptions in the ISCO scheme, and identifies which are most similar from a pure text perspective, suggesting the closest matches as the most appropriate class.\nMore specifically, it uses TF-IDF to turn text descriptions of scheme classes into numeric vectors that identify words particularly associated with different classes. By doing the same with the text inputs, and ranking its similarity to those for the scheme classes, it returns the “most suitable” matches.\nImportantly, it should be stressed that -at its core- this process works purely with word frequency/commonality. There is no (explicit) consideration or “understanding” of context, and accuracy of matches rely purely on sufficient detail being available in both the text input and the class descriptions in the scheme, and the being sufficiently distinct.\nObvious limitations aside, this approach is well established (TF-IDF is a widely used technique in Natural Language Processing), is quick to implement, and in most scenarios is very fast.\n\nApplication and performance\nFor a demonstration of the use of occupationcoder-international, and performance tests, see HERE.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#classifai",
    "href": "index.html#classifai",
    "title": "Introduction",
    "section": "classifai",
    "text": "classifai\nclassifai is a general classifcation tool using (Large) Language Models to vectorise scheme and input text. The overall logic is very similar to occupationcoder-international, in that both the scheme and input text are turned into numerical vectors, compared and ranked by similarity.\nThe key difference is that classifai uses pre-trained (Large) Language Models to do this vectorisation. Such models produce context-aware embeddings, which means that when used as vectorisers, they can provide some level of “understanding” of context.\nFor example, a good pre-trained Language Model shown the phrase “tuktuk” would likely associate this with “motorised rickshaw driver” or similar. By contrast, unless “tuktuk” is explicitly given in the coding scheme, a TF-IDF based approach would fail, because there simply is no word-based link between this input phrase and any class in the scheme.\nWhile the ability to consider context may represent a significant advantage, it should be noted that the use of pre-trained models as vectorisers can be restricted in certain circumstances, and their use can be more computationally intensive compared to TF-IDF (but, depending on implementation, this can be effectively managed).\n\nApplication and performance\nFor a demonstration of the use of classifai (specifically for classifying jobs to ISCO-08), and performance tests, see HERE.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "example_data.html",
    "href": "example_data.html",
    "title": "Synthetic example data for occupation coding",
    "section": "",
    "text": "This repository includes a data file containing example text descriptions of occupations (including tasks, industry etc), coded to the ISCO-08 International Standard Classification of Occupations scheme.\nThese data are synthetic. However, the examples are based on and inspired by the kind of text inputs we have seen in real-world examples.\n\n\nIn the example data, based on a combination of the job title, job description and industry description, at least one ISCO code was assigned as accurately as possible, and where relevant, a comment has been included.\nIn addition, the example data is grouped according to “Type”. This is intended to allow examples to be classified according to a variety of potential issues when assigning codes. These classes are intended to flag example cases that are ambiguous in some way, or have significant issues (like spelling mistakes in input). In effect, such examples are explicitly included to reflect real-world challenges when coding input data - providing a route to test performance of various coding tools given different types of challenges.\n\n\n\nTo allow unbiased comparison of coding accuracy (e.g. of different coding tools), it is key to test outputs on common benchmark data.\nWhile in an ideal world, accuracy tests would use “real world” census data that has been manually coded by clerical coders, we are not aware of such a data set that is both (1) publicly accessible and (2) has been validated thoroughly (i.e. cross-coded by different coders, and revised as needed). Even if available, using such real-world data does not allow for any control over, or analysis of, different potential issues with the input data: e.g. flagging of ambiguous cases as set out below.\n\n\nThus, the example data included in this repository has two different intended purposes:\n\nProvision of a common benchmark of text data pre-coded to ISCO codes, to allow comparisons of the efficacy of different (semi-automated) coding tools.\nProvision of a route to analyse performance of such coding tools given different potential challenges (e.g. input ambiguity, see below).\n\n\nWhile these data are synthetic, the intent is to make them reflect real-world scenarios as closely as possible. Thus, the examples deliberately include not only cases that are expected to be easy/straightforward to code, but also ones that are deliberately intended to be challenging - while being explicit about the reasons for this.\nWe stress that, despite the advantages over real-world data listed above, this synthetic data approach does have limitations, and we encourage review of and feedback on the example data, particularly in terms of how it reflect real-world samples.",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#background-and-context",
    "href": "example_data.html#background-and-context",
    "title": "Synthetic example data for occupation coding",
    "section": "",
    "text": "This repository includes a data file containing example text descriptions of occupations (including tasks, industry etc), coded to the ISCO-08 International Standard Classification of Occupations scheme.\nThese data are synthetic. However, the examples are based on and inspired by the kind of text inputs we have seen in real-world examples.\n\n\nIn the example data, based on a combination of the job title, job description and industry description, at least one ISCO code was assigned as accurately as possible, and where relevant, a comment has been included.\nIn addition, the example data is grouped according to “Type”. This is intended to allow examples to be classified according to a variety of potential issues when assigning codes. These classes are intended to flag example cases that are ambiguous in some way, or have significant issues (like spelling mistakes in input). In effect, such examples are explicitly included to reflect real-world challenges when coding input data - providing a route to test performance of various coding tools given different types of challenges.\n\n\n\nTo allow unbiased comparison of coding accuracy (e.g. of different coding tools), it is key to test outputs on common benchmark data.\nWhile in an ideal world, accuracy tests would use “real world” census data that has been manually coded by clerical coders, we are not aware of such a data set that is both (1) publicly accessible and (2) has been validated thoroughly (i.e. cross-coded by different coders, and revised as needed). Even if available, using such real-world data does not allow for any control over, or analysis of, different potential issues with the input data: e.g. flagging of ambiguous cases as set out below.\n\n\nThus, the example data included in this repository has two different intended purposes:\n\nProvision of a common benchmark of text data pre-coded to ISCO codes, to allow comparisons of the efficacy of different (semi-automated) coding tools.\nProvision of a route to analyse performance of such coding tools given different potential challenges (e.g. input ambiguity, see below).\n\n\nWhile these data are synthetic, the intent is to make them reflect real-world scenarios as closely as possible. Thus, the examples deliberately include not only cases that are expected to be easy/straightforward to code, but also ones that are deliberately intended to be challenging - while being explicit about the reasons for this.\nWe stress that, despite the advantages over real-world data listed above, this synthetic data approach does have limitations, and we encourage review of and feedback on the example data, particularly in terms of how it reflect real-world samples.",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#contributing-examples",
    "href": "example_data.html#contributing-examples",
    "title": "Synthetic example data for occupation coding",
    "section": "Contributing examples",
    "text": "Contributing examples\nWe welcome suggested additions to these example data. Indeed, the bigger the benchmark data set, the better any validation could be. Any proposed additions or changes should be made by making changes to the example file and including these in a formal Pull Request to the repository code.\nAs a minimum, when adding new examples, please include a unique sequential ID number, a job TITLE, and at least one expected ISCO code which should be assigned to it (MANUAL_ISCO1). For further detail, see “Example data format & structure” below.\n\nBecause these data are used to test and compare coding approaches, it is vital such data (1) adhere to the core purpose/aims specified above; and (2) are formatted correctly.\nWhen proposing additions please ensure you carefully consider the purpose and take note of the format requirements set out below.\nAny additions will be reviewed before inclusion in the main branch of the repo and the authors reserve the right to reject additions and do not commit to specifying reasons for this.",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#data-format-structure",
    "href": "example_data.html#data-format-structure",
    "title": "Synthetic example data for occupation coding",
    "section": "Data format & structure",
    "text": "Data format & structure\nThe example data file is in CSV format to maximise accessibility, interchangeability, while minimising potential cross-platform formatting issues.\nThe file has strict formatting requirements: these are enforced using validation code, and any changes or additions to the data require validation to be passed before further code is run. For details see sections below, but in general:\n\nA fixed number of expected columns (see below): if more or less columns are found, validation fails.\n\nExact column naming as below\n\nSome columns can’t have missing values\n\nGiven ISCO codes have to be valid (ie included in the coding scheme)\n\n\n\n\n\n\n\n\nTable 1: Example data columns and data types\n\n\n\n\n\nColumn\nDescription\nMissing allowed?\nValue\n\n\n\n\nID\nUnique sequential ID number for example\nNo\nInteger\n\n\nTITLE\nText input: short job title\nNo\nFree text\n\n\nTASKS\nText input: longer description of job and tasks involved\nYes\nFree text\n\n\nINDUSTRY\nText input: description of industry for the job\nYes\nFree text\n\n\nMANUAL_ISCO1\nFirst candidate ISCO-08 code (most preferred)\nNo\nValid ISCO code (1-4 digits)\n\n\nMANUAL_ISCO2\nSecond candidate ISCO-08 code\nYes\nValid ISCO code (1-4 digits)\n\n\nMANUAL_ISCO3\nThird candidate ISCO-08 code\nYes\nValid ISCO code (1-4 digits)\n\n\nTYPE\nType of example (see detail below)\nYes\nOne of a fixed number of types (see below), or missing (empty)\n\n\nCOMMENT\nComments\nYes\nFree text\n\n\n\n\n\n\n\n\n\nExample types\nIn the example data file, the TYPE value should be one of a fixed number of classes (see table below). It can also be left blank/empty - implying that no issues are expected with the “codeability” of the example.\nTYPE is included in the example file to allow analyses of potential mismatches between the manually assigned codes, and the potential predictions by coding tools. It is important to stress that such mismatches can occur due to a variety of reasons - they may reflect genuine mistakes on the part of the enumerators or clerical coders; they may reflect ambiguity in the text inputs and therefore imply a level of subjectivity in the choice of code; or it may be due to ambiguity in the coding scheme itself.\nWhile the example data set is intended to be coded as accurately as possible (ie. excluding straight errors in coding), the TYPE value in the data flags cases where we think mismatches between manual and predicted codes are still likely to happen (due to, for example, ambiguity in the input - see below). In addition, different TYPE classes provide some information on why we think that is the case.\n\n\n\n\n\n\n\nTable 2: Example data columns and data types\n\n\n\n\n\nType\nDescription\n\n\n\n\nExact match\nExpecting an 'exact match': job title is explicitly included in the ISCO-08 scheme\n\n\nExact match fail\nExpecting an exact match as above, but not coded as such (ie. strictly speaking, a coding error)\n\n\nSemantic ambiguity\nText inputs combined are semantically ambiguous (e.g. lack of detail means different codes could apply)\n\n\nScheme ambiguity\nAmbiguity caused (predominantly) by structure/detail in the scheme, rather than the text inputs per se\n\n\nDeeper ambiguity\nA combination of different types of ambiguity of inputs and scheme\n\n\nInput issue\nIssues like misspellings in text inputs\n\n\n\nBlank values for type means no coding issues are expected\n\n\n\n\n\n\n\n\n\n“Exact” matches\nThe ISCO-08 scheme includes examples of job titles that are expected to be directly associated with specific classes/codes. For example, “Ambassador” is included as a match to “Senior Government Officials (1112)”; and “Environmental analyst” is included as a match to “Environmental Engineers (2143)”.\n\nExact match. Cases where an exact match is expected based on the TITLE given and specification in the coding scheme, should be classed as TYPE “Exact match” in the example data.\n\n\nExact match fail. Cases (reflecting real-world examples) where enumerators or clerical coders have not have assigned expected exact matches strictly correctly.\n\n\n\nAmbiguous cases\nIn many practical cases, text input describing occupations can be ambiguous in terms of classification to the scheme.\nThis is most apparent in cases where detail is lacking in text inputs. Extreme examples are “farmer” or “teacher”: in both cases, the scheme requires significantly more detail to allow confident coding to any level of granularity in the scheme. For “farmer”, for coding to 4 digits, ISCO-08 expects differentiation between e.g. livestock and crop farmers; or subsistence and commercial farmer. For “teacher”, 4-digit coding requires detail on the level of education, e.g. primary or secondary.\nSimilar to the ‘exact match’ example types above, the TYPE classes in the examples attempts to distinguish between three (partly overlapping/subjective) subtypes as listed below. Note that the assignment of these is (to some extent) open to interpretation, but an attempt is made to distinguish these to help potential for deeper analyses and comparisons.\n\nSemantic ambiguity. These are cases where, given the text input, some level of semantic “understanding” is required to code to the correct class.\nFor example, “Kapana seller” is understood in some African countries as being a street food seller, i.e. 5212 in ISCO-08. However, as the scheme does not include any specific reference to this, this input requires broader semantic and contextual understanding of the meaning of this phrase. Whereas some coding tools (e.g. ClassifAI) may use language models that provide such context; others (e.g. occupationcoder-international) rely on string similarity, which would fail on this match as it does not include that broader context.\n\n\nScheme ambiguity. These are cases where the ambiguity is primarily due to limitations of the coding scheme, rather than the detail in the text input.\nFor example, “data scientist” as title alongside a fairly detailed description of the job is challenging to assign to a specific code in the scheme. This is because this class of job is simply not included in the scheme and potentially overlaps multiple classes. So, the assignment will need to be a compromise depending on the nuance in the text input. As with semantic ambiguity, in some limited cases, tools that are based on language models as opposed to (fuzzy) string matchers may help in these cases, but they are still likely to be limited in terms of potential for disambiguation.\n\n\nDeeper ambiguity. These are cases where there is ambiguity of the types described above, but it is unclear which specifically; or the issue is a combination of factors. Such cases are likely to be challenging to code regardless of the approach used: in some cases, correct strict application of the coding scheme may require limiting coding to three- or two-digit levels (less granularity).\n\n\n\nInput issues\nThese are cases where the likely coding issue is due to input errors such as spelling mistakes. For example, “barbar” instead of “barber”. While this should be codeable with a level of contextual understanding of language, more basic tools such as fuzzy- or string matchers will struggle.",
    "crumbs": [
      "Example data"
    ]
  }
]