[
  {
    "objectID": "demos_performance.html",
    "href": "demos_performance.html",
    "title": "Example applications and performance",
    "section": "",
    "text": "The following serves as a demonstration/tutorial of how to apply the occupation coding tools on some example data, including full code examples as a tutorial/walkthrough. We also show some tests to compare tool predictions to manually assigned codes in the example data, to serve as basic accuracy tests.\nFurther background to the process and techiques used are set out in these pages. For details on the example data used, see here.\nAll the following examples assume you have a working Python install on your system.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#initial-set-up",
    "href": "demos_performance.html#initial-set-up",
    "title": "Example applications and performance",
    "section": "Initial set up",
    "text": "Initial set up\nTo install occupationcoder-international, you can install the package directly from its Github repository using pip, as set out here. Alternatively, installing the requirements.txt for the present repository will also install everything required.\nThe package comes with a “dictionary” for the ISCO-08 coding scheme, so there is no need to set this up manually.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#coding-the-examples",
    "href": "demos_performance.html#coding-the-examples",
    "title": "Example applications and performance",
    "section": "Coding the examples",
    "text": "Coding the examples\nWhile occupationcoder-international comes with a script that allows it to be run on an input file directly from the command line, we here demonstrate its use in Python code, as a module. We assume this is the most likely approach for embedding this tool into existing (Python) pipelines.\nTo load the required modules, set up the coder class, and load the example data, you can do the following:\n\nimport pandas as pd\nfrom oc3i import Coder\n\n# Initialise the coder with the desired coding scheme (here ISCO):\ncoder = Coder(scheme = \"isco\")\n\n# Load the example data (please adjust the file path as needed on your machine)\nexample_data = pd.read_csv(\"../data/isco_benchmark_data.csv\", dtype={'MANUAL_ISCO1': str, 'MANUAL_ISCO2': str, 'MANUAL_ISCO3': str})\n#example_data.head()\n\n\n# Code the example using all text in the TITLE, TASKS and INDUSTRY columns.\nexample_coded = coder.code_data_frame(example_data, \n                                        title_column = \"TITLE\", \n                                        description_column = \"TASKS\", \n                                        sector_column = \"INDUSTRY\")\n#example_coded.head()\n\nCoding 85 records in dataframe...\nWarning: Column 'INDUSTRY' contains 34 missing values. These will be interpreted as empty strings.\nWarning: Column 'TASKS' contains 6 missing values. These will be interpreted as empty strings.\n\n\nWe can now assess performance of occupationcoder-international, by calculating “accuracy” as the number of cases where the top predicted code matches the manually assigned code exactly:\n\n# Accuracy 1: number of cases where top prediction matches the preferred manually assigned code:\nmatch1 = (example_coded[\"MANUAL_ISCO1\"] == example_coded[\"prediction 1\"]).sum()\n#print(match1)\n\nAlternatively, we can be less conservative and also consider cases where either the top 1, 2 or 3 prediction matches the manually assigned code (i.e. assuming a user uses the tool to suggest potential alternative options):\n\n# Accuracy 2: number of cases where manually assigned code is included in the top 3 predictions:\nmatch123 = example_coded[\"MANUAL_ISCO1\"].isin(\n                example_coded[[\"prediction 1\", \"prediction 2\", \"prediction 3\"]].values.flatten()\n           ).sum()\n#print(match123)\n\nTo avoid needing to re-run the same calculation every time, we can wrap the above in a short function that also calculates the % of the total (note, the following code is deliberately verbose for demonstration purposes - we suggest this is optimised and expanded on in production settings):\n\ndef matches(dat, preds, output = \"both\"):\n\n    # Calculate number of matches to \"best\" prediction:\n    match1 = (dat[\"MANUAL_ISCO1\"] == dat[preds[0]]).sum()\n\n    # Calculate number of matches to any of the top 3 predictions:\n    match123 = dat[\"MANUAL_ISCO1\"].isin(\n                   dat[preds].values.flatten()\n               ).sum()\n\n    # Calculate proportions:\n    match1p = (match1/len(dat))*100\n    match123p = (match123/len(dat))*100\n\n    # Ouput match count, proportion or both - formatted as strings:\n    if output == \"both\":\n        return([f\"{match1} ({match1p:.1f}%)\", f\"{match123} ({match123p:.1f}%)\"])\n    if output == \"abs\":\n        return([f\"{match1}\", f\"{match123}\"])\n    if output == \"prop\":\n        return([f\"{match1p:.1f}%\", f\"{match123p:.1f}%\"])\n\nWe can now use this function to calculate performance on different subsets of the data.\nFor example, we first split the full example data set by TYPE (for a more detailed explanation of these data TYPES, see here). Specifically, we split by (1) cases where we expect an exact match; (2) cases that should be codeable but not an exact match; (3) cases we expect to be challenging due to ambiguity:\n\nt1 = example_coded[example_coded[\"TYPE\"] == \"Exact match\"]\nt2 = example_coded[example_coded[\"TYPE\"].isna()]\nt3 = example_coded[example_coded[\"TYPE\"].str.contains('ambigui', case=False, na=False)]\n\nNow we can use our function above on the full example data set, as well as the subsets, and collate a summary table (note that the code below does not follow best practice; this is deliberate to ensure maximum accessibility):\n\npreds1 = [\"prediction 1\", \"prediction 2\", \"prediction 3\"]\nsummary1 = [\n    [\"All examples\", len(example_coded),matches(example_coded, preds1)[0],matches(example_coded, preds1)[1]],\n    [\"Expected exact match\", len(t1), matches(t1, preds1)[0],matches(t1, preds1)[1]],\n    [\"Expected codeable\", len(t2), matches(t2, preds1)[0],matches(t2, preds1)[1]],\n    [\"Expected ambiguity\", len(t3), matches(t3, preds1)[0],matches(t3, preds1)[1]]\n]\nsummary1 = pd.DataFrame(summary1, columns = [\"Type\",\"Total\", \"Match to 1\",\"Match in 1-3\",])\n\nThe output of the above is shown in the following section.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#occpationcoder-accuracy",
    "href": "demos_performance.html#occpationcoder-accuracy",
    "title": "Example applications and performance",
    "section": "Occpationcoder accuracy",
    "text": "Occpationcoder accuracy\nMatch counts and rates between manually assigned codes, and those produced by occupationcoder-international are given in the table below.\n\n\n\n\n\n\n\nTable 1: occupationcoder-international 'accuracy', estimated as match rates between manually assigned occupation codes and either the highest ranked match ('Match to 1'), or as a match to any of the best 3 matches ('Match in 1-3'), grouped by either all examples or examples split by type.\n\n\n\n\n\nType\nTotal\nMatch to 1\nMatch in 1-3\n\n\n\n\nAll examples\n85\n42 (49.4%)\n66 (77.6%)\n\n\nExpected exact match\n17\n17 (100.0%)\n17 (100.0%)\n\n\nExpected codeable\n40\n17 (42.5%)\n30 (75.0%)\n\n\nExpected ambiguity\n25\n6 (24.0%)\n14 (56.0%)\n\n\n\n\n\n\n\n\nThe above results show that:\n\nWhen considering all of the example data in 49.4% of cases, the top prediction from occupationcoder-international agrees with a manually assigned code. When interpreting a “match” as the manual code being included in the top 3 predictions, this increases to 77.6% cases. It is worth stressing this includes all example cases we a priori expected to be challenging.\n\nAs expected, direct match rates are much lower for known ambiguous cases (24.0%); but this is much improved by also considering the top 3 predictions (56.0%).\nLess informative (as this is a feature of occupationcoder-international, but nevertheless a good sense check), in all cases where we expected an exact match, this is matched correctly.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#initial-set-up-1",
    "href": "demos_performance.html#initial-set-up-1",
    "title": "Example applications and performance",
    "section": "Initial set up",
    "text": "Initial set up\nClassifai can be installed either by following the instructions provided with its repository (recommended method); or as of the time of writing this, by installing the requirements for the present repository (noting that this may change as classifai is under active development).\nNote that for the purposes of this example and tests, we here use a Huggingface model as the vectoriser - Classifai can use other models and performance may vary. We also stress that vectorising the entire coding scheme takes some time, so it is worth doing this once, and re-using a saved copy when running queries. This minimises processing overhead.",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#processing-the-data",
    "href": "demos_performance.html#processing-the-data",
    "title": "Example applications and performance",
    "section": "Processing the data",
    "text": "Processing the data\nWe first need to retrieve the raw ISCO coding scheme data, and convert into a format that can be vectorised by Classifai.\nThe following sets download targets for the scheme (note this uses a copy included with occuptioncoder-international; it can also be sourced from the ILO website) and local save locations.\n\nISCO_DATA_SOURCE = \"https://raw.githubusercontent.com/datasciencecampus/occupationcoder-international/main/data/ISCO-08%20EN%20Structure%20and%20definitions.xlsx\"\nISCO_DATA_FILE = \"../data/ISCO-08-scheme.xlsx\" # Please adjust this path as required if running this code on your machine\nPROCESSED_ISCO_DATA = \"../data/ISCO-08-processed.csv\" # Please adjust this path as required if running this code on your machine\n\nWe can now download and save the ISCO file using a simple helper function included with this repository:\n\nimport os, sys\nsys.path.append(os.path.abspath(\"..\"))\nfrom src.utils import get_isco_scheme_data\nif not os.path.exists(ISCO_DATA_FILE):\n    get_isco_scheme_data(source_url=ISCO_DATA_SOURCE, local_file_path=ISCO_DATA_FILE)\n\nThe ISCO-08 scheme consists of separate columns containing the ISCO code, the corresponding title, and various description fields. We here chose to simply concatenate the latter, resulting in a raw input file with two columns: ISCO code, and all description for that code. For the sake of simplicity, we provide a helper function that does this; used as follows:\n\nfrom src.utils import process_excel_to_csv\nprocess_excel_to_csv(ISCO_DATA_FILE, PROCESSED_ISCO_DATA)\n\nFiltered and processed data saved to ../data/ISCO-08-processed.csv",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#create-vector-store",
    "href": "demos_performance.html#create-vector-store",
    "title": "Example applications and performance",
    "section": "Create vector store",
    "text": "Create vector store\nNow that we have the scheme data processed in a format that can be used easily by Classifai, we download our chosen model for this example (all-mpnet-base-v2).\n\nfrom classifai.vectorisers import HuggingFaceVectoriser\nfrom classifai.indexers import VectorStore\nhf_vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/classifai/indexers/main.py:38: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can now use this model and the Classifai functions to create a local vector database from the scheme data. As above, we only need to do this once on a given machine - so the code below first checks whether we already have a previously created store, and loads this if available. Otherwise, it creates a new one.\n\nif not os.path.exists(\"../data/hf_vectoriser\"):\n    hf_vector_store = VectorStore(\n        file_name=\"../data/ISCO-08-processed.csv\",\n        data_type=\"csv\",\n        vectoriser=hf_vectoriser,\n        output_dir=\"../data/hf_vectoriser\",\n        overwrite=True\n    )\nelse:\n    hf_vector_store = VectorStore.from_filespace(folder_path=\"../data/hf_vectoriser\",vectoriser=hf_vectoriser)\n\nINFO - Processing file: ../data/ISCO-08-processed.csv...\n\n\n\n\n\n\nINFO - Gathering metadata and saving vector store / metadata...\nINFO - Vector Store created - files saved to ../data/hf_vectoriser",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#coding-the-examples-1",
    "href": "demos_performance.html#coding-the-examples-1",
    "title": "Example applications and performance",
    "section": "Coding the examples",
    "text": "Coding the examples\nNow that we have the local vector database from the scheme, we can use Classifai to code the example data. For the purposes of this example, we simply extract all available input text (ie job title, tasks description and industry description) from the example data, and combine this into a single string.\n\njobs = example_coded[\"TITLE\"] + \" \" + example_coded[\"TASKS\"] + \" \" + example_coded[\"INDUSTRY\"]\nclassifai_coded = hf_vector_store.search(jobs.tolist(), n_results=3)\n\n\n\n\nClassifai outputs results in a longitudinal format where “rank” 0-2 indicates the first, second and third best match respectively. For convenience, we here extract each of these in turn for a given example, and add these as coluns to our example coded data set.\n\nexample_coded[\"classifai_p0\"] = classifai_coded[classifai_coded[\"rank\"]==0][\"doc_id\"].values\nexample_coded[\"classifai_p1\"] = classifai_coded[classifai_coded[\"rank\"]==1][\"doc_id\"].values\nexample_coded[\"classifai_p2\"] = classifai_coded[classifai_coded[\"rank\"]==2][\"doc_id\"].values\n\nWe can now compare the manually assigned code to the ones top 3 matches provided by Classifai, following the same approach as for occupationcoder-international as above. We first extract subsets of the data for expected exact matches, expected codeable, and expected ambiguous examples:\n\nt1a = example_coded[example_coded[\"TYPE\"] == \"Exact match\"]\nt2a = example_coded[example_coded[\"TYPE\"].isna()]\nt3a = example_coded[example_coded[\"TYPE\"].str.contains('ambigui', case=False, na=False)]\n\nWe then use the same macthing function defined above - but this time using the Classifai predictions.\n\npreds2 = [\"classifai_p0\", \"classifai_p1\", \"classifai_p2\"]\nsummary2 = [\n    [\"All examples\", len(example_coded),matches(example_coded, preds2)[0], matches(example_coded, preds2)[1]],\n    [\"Expected exact match\", len(t1a), matches(t1a, preds2)[0],matches(t1a, preds2)[1]],\n    [\"Expected codeable\", len(t2a), matches(t2a, preds2)[0],matches(t2a,preds2)[1]],\n    [\"Expected ambiguity\", len(t3a), matches(t3a, preds2)[0],matches(t3a, preds2)[1]]\n]\nsummary2 = pd.DataFrame(summary2, columns = [\"Type\",\"Total\", \"Match to 1\",\"Match in 1-3\",])",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "demos_performance.html#classifai-accuracy",
    "href": "demos_performance.html#classifai-accuracy",
    "title": "Example applications and performance",
    "section": "Classifai accuracy",
    "text": "Classifai accuracy\nMatch counts and rates between manually assigned codes, and those produced by Classifai are given in the table below.\n\n\n\n\n\n\n\nTable 2: Classifai 'accuracy', estimated as match rates between manually assigned occupation codes and either the highest ranked match ('Match to 1'), or as a match to any of the best 3 matches ('Match in 1-3'), grouped by either all examples or examples split by type.\n\n\n\n\n\nType\nTotal\nMatch to 1\nMatch in 1-3\n\n\n\n\nAll examples\n85\n47 (55.3%)\n75 (88.2%)\n\n\nExpected exact match\n17\n13 (76.5%)\n16 (94.1%)\n\n\nExpected codeable\n40\n23 (57.5%)\n37 (92.5%)\n\n\nExpected ambiguity\n25\n10 (40.0%)\n16 (64.0%)\n\n\n\n\n\n\n\n\n\nAcross all of the example data in 55.3% of cases, the top prediction from Classifai agrees with a manually assigned code. When interpreting a “match” as the manual code being included in the top 3 predictions, this increases to 88.2% cases. It is worth stressing this includes all example cases we a priori expected to be challenging.\n\nMatch rates to the top predictions are lower for known ambiguous cases (40.0%); but this is much improved by also considering the top 3 predictions (64.0%).",
    "crumbs": [
      "Demo & performance"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "With this repository, we aim to provide a demonstration of:\nWe compare two tools that can support the occupation coding process - occupationcoder-international and Classifai. Other tools are available. It is also worth stressing that in the way they are used here, the tools themselves should be seen as just a small part of a wider coding “pipeline”. For example, in production settings, it will be important to embed the workflow set out here into a wider process that might include initial data processing, but also post-processing steps that might involve (for example) confirming final classification.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#what-is-occupation-coding",
    "href": "index.html#what-is-occupation-coding",
    "title": "Introduction",
    "section": "What is “occupation coding”",
    "text": "What is “occupation coding”\nNational Statistics Organisations (NSOs) collect data on respondents’ occupations through surveys such as Labour Force Surveys and Censuses. Enumerators record brief text answers to questions like “What job have you done in the last X months?” and “What tasks did it involve?”\nUsing these short descriptions, enumerators or later clerical coders assign one or more classes from an occupational coding scheme (e.g., ISCO-08). These schemes link job descriptions to standardised numeric codes, enabling consistent reporting and international comparability. While ISCO-08 is the international standard, many countries use adapted national versions (e.g., the UK’s SOC or Namibia’s NASCO).\nCoding schemes are hierarchical, with each numeric code representing a class that includes a title (e.g., “Psychologists”), a task description, and common job titles. Higher-level groups encompass more specific ones, with hierarchy reflected in the number of digits in the code. If a description is ambiguous, coders may assign multiple possible codes or fall back to a higher-level category.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#common-challenges",
    "href": "index.html#common-challenges",
    "title": "Introduction",
    "section": "Common challenges",
    "text": "Common challenges\nAccurate classification of job descriptions depends on coders correctly applying the coding scheme and understanding its scope and limitations. This requires substantial training and ongoing skill maintenance, which is often underresourced, leading to data quality issues.\nEnumerators must probe for sufficient detail to enable precise coding, while clerical coders need a clear grasp of the data’s constraints, the scheme, and the dataset’s intended use. Coding frequently involves trade-offs, selecting multiple plausible codes, and maintaining consistent procedures.\nConsistency is both essential and difficult to achieve. Even well-trained coders may classify ambiguous descriptions differently or struggle when the scheme lacks detail. Ideally, validation—such as double-blind coding with reconciliation of discrepancies—would be widespread, but this can be impractical for large surveys with millions of records due to the resources required.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#purpose-of-coding-tools",
    "href": "index.html#purpose-of-coding-tools",
    "title": "Introduction",
    "section": "Purpose of coding tools",
    "text": "Purpose of coding tools\nOccupation coding tools aim to reduce the workload of coding, especially during validation. They should be seen as assistive tools, not fully autonomous coders: limited input data and coarse coding schemes mean that ambiguity faced by humans also affects any coding tool. Thus, keeping a human in the loop is crucial, particularly for business-critical outputs.\nIn the application demonstrated here, we focus on workflows where manually assigned codes already exist (ie after data collection), with the tools helping to review and potentially revise them. Although they could be integrated into data-collection software (e.g. CSPro), the focus is on their role in data processing, not collection. When used as such, the tools have the potential to significantly increase efficiency by (1) filtering out cases that do not need any revision as the manual codes agree with tool predictions; and (2) for those cases that do need review, provide (ranked) alternative (better) choices.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#occupationcoder-international",
    "href": "index.html#occupationcoder-international",
    "title": "Introduction",
    "section": "occupationcoder-international",
    "text": "occupationcoder-international\noccupationcoder-international is a string “fuzzy matching” tool, extending an existing tool for the UK SOC scheme to the international ISCO one.\nIn brief, occupationcoder-international compares a given text input to each of the class descriptions in the ISCO scheme, and identifies which are most similar from a pure text perspective, suggesting the closest matches as the most appropriate class.\nMore specifically, it uses TF-IDF to turn text descriptions of scheme classes into numeric vectors that identify words particularly associated with different classes. By doing the same with the text inputs, and ranking its similarity to those for the scheme classes, it returns the “most suitable” matches.\nImportantly, it should be stressed that -at its core- this process works purely with word frequency/commonality. There is no (explicit) consideration or “understanding” of context, and accuracy of matches rely purely on sufficient detail being available in both the text input and the class descriptions in the scheme, and the being sufficiently distinct.\nObvious limitations aside, this approach is well established (TF-IDF is a widely used technique in Natural Language Processing), is quick to implement, and in most scenarios is very fast.\n\nApplication and performance\nFor a demonstration of the use of occupationcoder-international, and performance tests, see HERE.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#classifai",
    "href": "index.html#classifai",
    "title": "Introduction",
    "section": "classifai",
    "text": "classifai\nClassifai is a general vector search tool using (Large) Language Models to vectorise scheme and input text. It can be used to identify the best match(es) between input text and specific sections of a corpus, such as a coding scheme. The overall logic is very similar to occupationcoder-international, in that both the scheme and input text are turned into numerical vectors, compared and ranked by similarity.\nThe key difference is that Classifai uses pre-trained (Large) Language Models to do this vectorisation. Such models produce context-aware embeddings, which means that when used as vectorisers, they can provide some level of “understanding” of context.\nFor example, a good pre-trained Language Model shown the phrase “tuktuk” would likely associate this with “motorised rickshaw driver” or similar. By contrast, unless “tuktuk” is explicitly given in the coding scheme, a TF-IDF based approach would fail, because there simply is no word-based link between this input phrase and any class in the scheme.\nWhile the ability to consider context may represent a significant advantage, it should be noted that the use of pre-trained models as vectorisers can be restricted in certain circumstances, and their use can be more computationally intensive compared to TF-IDF (but, depending on implementation, this can be effectively managed).\n\nApplication and performance\nFor a demonstration of the use of classifai (specifically for classifying jobs to ISCO-08), and performance tests, see HERE.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "example_data.html",
    "href": "example_data.html",
    "title": "Synthetic example data for occupation coding",
    "section": "",
    "text": "This repository includes a synthetic data file containing example text descriptions of occupations (including tasks, industry etc), coded to the ISCO-08 International Standard Classification of Occupations scheme.\n\n\nThe example data combine job titles, descriptions, and industry information to assign one or more ISCO codes as accurately as possible, with comments added where relevant.\nThese synthetic cases were built from varied sources—job adverts, example job descriptions, including ones inspired by real-world census or survey data we have seen in a range of English-speaking countries (including the UK and numerous African countries). Note that for reasons of data confidentiality, no examples included are directly taken from such datasets.\nEach case was manually coded using the ISCO-08 scheme, focusing on listed example jobs, class titles, and task descriptions. This requires interpretation and contextual understanding (e.g., “senior dev at gaming company” implies “Software Developer”). Although up to three codes can be stored, most cases currently have a single manual code. Currently, all examples were compiled and coded by one (non-specialist) coder, so the dataset has limitations; contributions and review are encouraged.\nEach record is also assigned a “Type” to indicate potential coding issues—such as ambiguity or spelling errors—capturing real-world challenges and enabling tests of coding tools under different conditions.\n\n\n\nTo compare coding accuracy between tools, a shared benchmark is essential.\nIdeally, this would be real-world data thoroughly coded and validated by clerical coders, but we are not aware of publicly accessible, rigorously cross-checked datasets that meet these requirements. Even if available, real-world data could not isolate or analyse specific input-data issues (e.g., known ambiguous cases).\n\n\n\nThe dataset included here serves two purposes: (1) to provide a common benchmark of text inputs pre-coded to ISCO for comparing coding tools; and (2) to enable analysis of tool performance, including under specific challenges (e.g., ambiguous input).",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#background-and-context",
    "href": "example_data.html#background-and-context",
    "title": "Synthetic example data for occupation coding",
    "section": "",
    "text": "This repository includes a synthetic data file containing example text descriptions of occupations (including tasks, industry etc), coded to the ISCO-08 International Standard Classification of Occupations scheme.\n\n\nThe example data combine job titles, descriptions, and industry information to assign one or more ISCO codes as accurately as possible, with comments added where relevant.\nThese synthetic cases were built from varied sources—job adverts, example job descriptions, including ones inspired by real-world census or survey data we have seen in a range of English-speaking countries (including the UK and numerous African countries). Note that for reasons of data confidentiality, no examples included are directly taken from such datasets.\nEach case was manually coded using the ISCO-08 scheme, focusing on listed example jobs, class titles, and task descriptions. This requires interpretation and contextual understanding (e.g., “senior dev at gaming company” implies “Software Developer”). Although up to three codes can be stored, most cases currently have a single manual code. Currently, all examples were compiled and coded by one (non-specialist) coder, so the dataset has limitations; contributions and review are encouraged.\nEach record is also assigned a “Type” to indicate potential coding issues—such as ambiguity or spelling errors—capturing real-world challenges and enabling tests of coding tools under different conditions.\n\n\n\nTo compare coding accuracy between tools, a shared benchmark is essential.\nIdeally, this would be real-world data thoroughly coded and validated by clerical coders, but we are not aware of publicly accessible, rigorously cross-checked datasets that meet these requirements. Even if available, real-world data could not isolate or analyse specific input-data issues (e.g., known ambiguous cases).\n\n\n\nThe dataset included here serves two purposes: (1) to provide a common benchmark of text inputs pre-coded to ISCO for comparing coding tools; and (2) to enable analysis of tool performance, including under specific challenges (e.g., ambiguous input).",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#contributing-examples",
    "href": "example_data.html#contributing-examples",
    "title": "Synthetic example data for occupation coding",
    "section": "Contributing examples",
    "text": "Contributing examples\nWe welcome suggested additions to these example data. Any proposed additions or changes should be made by making changes to the example file and including these in a formal Pull Request to the repository code.\nAs a minimum, when adding new examples, please include a unique sequential ID number, a job TITLE, and at least one expected ISCO code which should be assigned to it (MANUAL_ISCO1). For further detail, see “Data format & structure” below.\nBecause these data are used to test and compare coding approaches, it is vital such data (1) adhere to the core purpose/aims specified above; and (2) are formatted correctly. When proposing additions, please ensure you carefully consider the purpose and take note of the format requirements set out below.\nAny additions will be reviewed before inclusion in the main branch of the repo and the authors reserve the right to reject additions and do not commit to specifying reasons for this.",
    "crumbs": [
      "Example data"
    ]
  },
  {
    "objectID": "example_data.html#data-format-structure",
    "href": "example_data.html#data-format-structure",
    "title": "Synthetic example data for occupation coding",
    "section": "Data format & structure",
    "text": "Data format & structure\nThe example data file is in CSV format to maximise accessibility, interchangeability, while minimising potential cross-platform formatting issues.\nThe file has strict formatting requirements: these are enforced using validation steps, and any changes or additions to the data require validation to be passed before further code is run. For details see sections below, but in general:\n\nA fixed number of expected columns (see below): if extra ones are found or some are missing, validation fails.\n\nExact column naming as below\n\nSome columns can’t have missing values\n\nGiven ISCO codes have to be valid (ie included in the coding scheme)\n\nTYPE values are one of a fixed number of categories, or left blank if no significant coding issues are expected.\n\n\n\n\n\n\n\n\nTable 1: Example data columns and data types\n\n\n\n\n\nColumn\nDescription\nMissing allowed?\nValue\n\n\n\n\nID\nUnique sequential ID number for example\nNo\nInteger\n\n\nTITLE\nText input: short job title\nNo\nFree text\n\n\nTASKS\nText input: longer description of job and tasks involved\nYes\nFree text\n\n\nINDUSTRY\nText input: description of industry for the job\nYes\nFree text\n\n\nMANUAL_ISCO1\nFirst candidate ISCO-08 code (most preferred)\nNo\nValid ISCO code (1-4 digits)\n\n\nMANUAL_ISCO2\nSecond candidate ISCO-08 code\nYes\nValid ISCO code (1-4 digits)\n\n\nMANUAL_ISCO3\nThird candidate ISCO-08 code\nYes\nValid ISCO code (1-4 digits)\n\n\nTYPE\nType of example (see detail below)\nYes\nOne of a fixed number of types (see below), or missing (empty)\n\n\nCOMMENT\nComments\nYes\nFree text\n\n\n\n\n\n\n\n\n\nExample types\nIn the example data file, the TYPE value should be one of a fixed number of classes (see table below). It can also be left blank/empty - implying that no issues are expected with the “codeability” of the example.\nTYPE is included in the example file to allow analyses of potential mismatches between the manually assigned codes, and the potential predictions by coding tools. It is important to stress that such mismatches can occur due to a variety of reasons - they may reflect genuine mistakes on the part of the enumerators or clerical coders; they may reflect ambiguity in the text inputs and therefore imply a level of subjectivity in the choice of code; or it may be due to ambiguity in the coding scheme itself.\nWhile the example data set is intended to be coded as accurately as possible (ie. excluding straight errors in coding), the TYPE value in the data flags cases where we think mismatches between manual and predicted codes are still likely to happen (due to, for example, ambiguity in the input - see below). In addition, different TYPE classes provide some information on why we think that is the case.\n\n\n\n\n\n\n\nTable 2: Example data columns and data types\n\n\n\n\n\nType\nDescription\n\n\n\n\nExact match\nExpecting an 'exact match': job title is explicitly included in the ISCO-08 scheme\n\n\nExact match fail\nExpecting an exact match as above, but not coded as such (ie. strictly speaking, a coding error)\n\n\nSemantic ambiguity\nText inputs combined are semantically ambiguous (e.g. lack of detail means different codes could apply)\n\n\nScheme ambiguity\nAmbiguity caused (predominantly) by structure/detail in the scheme, rather than the text inputs per se\n\n\nDeeper ambiguity\nA combination of different types of ambiguity of inputs and scheme\n\n\nInput issue\nIssues like misspellings in text inputs\n\n\n\nBlank values for type means no coding issues are expected\n\n\n\n\n\n\n\n\n\n“Exact” matches\nThe ISCO-08 scheme includes examples of job titles that are expected to be directly associated with specific classes/codes. For example, “Ambassador” is included as a match to “Senior Government Officials (1112)”; and “Environmental analyst” is included as a match to “Environmental Engineers (2143)”.\n\nExact match. Cases where an exact match is expected based on the TITLE given and specification in the coding scheme, should be classed as TYPE “Exact match” in the example data.\n\n\nExact match fail. Cases (reflecting real-world examples) where enumerators or clerical coders have not have assigned expected exact matches strictly correctly.\n\n\n\nAmbiguous cases\nIn many practical cases, text input describing occupations can be ambiguous in terms of classification to the scheme.\nThis is most apparent in cases where detail is lacking in text inputs. Extreme examples are “farmer” or “teacher”: in both cases, the scheme requires significantly more detail to allow confident coding to any level of granularity in the scheme. For “farmer”, for coding to 4 digits, ISCO-08 expects differentiation between e.g. livestock and crop farmers; or subsistence and commercial farmer. For “teacher”, 4-digit coding requires detail on the level of education, e.g. primary or secondary.\nSimilar to the ‘exact match’ example types above, the TYPE classes in the examples attempts to distinguish between three (partly overlapping/subjective) subtypes as listed below. Note that the assignment of these is (to some extent) open to interpretation, but an attempt is made to distinguish these to help potential for deeper analyses and comparisons.\n\nSemantic ambiguity. These are cases where, given the text input, some level of semantic “understanding” is required to code to the correct class.\nFor example, “Kapana seller” is understood in some African countries as being a street food seller, i.e. 5212 in ISCO-08. However, as the scheme does not include any specific reference to this, this input requires broader semantic and contextual understanding of the meaning of this phrase. Whereas some coding tools (e.g. ClassifAI) may use language models that provide such context; others (e.g. occupationcoder-international) rely on string similarity, which would fail on this match as it does not include that broader context.\n\n\nScheme ambiguity. These are cases where the ambiguity is primarily due to limitations of the coding scheme, rather than the detail in the text input.\nFor example, “data scientist” as title alongside a fairly detailed description of the job is challenging to assign to a specific code in the scheme. This is because this class of job is simply not included in the scheme and potentially overlaps multiple classes. So, the assignment will need to be a compromise depending on the nuance in the text input. As with semantic ambiguity, in some limited cases, tools that are based on language models as opposed to (fuzzy) string matchers may help in these cases, but they are still likely to be limited in terms of potential for disambiguation.\n\n\nDeeper ambiguity. These are cases where there is ambiguity of the types described above, but it is unclear which specifically; or the issue is a combination of factors. Such cases are likely to be challenging to code regardless of the approach used: in some cases, correct strict application of the coding scheme may require limiting coding to three- or two-digit levels (less granularity).\n\n\n\nInput issues\nThese are cases where the likely coding issue is due to input errors such as spelling mistakes. For example, “barbar” instead of “barber”. While this should be codeable with a level of contextual understanding of language, more basic tools such as fuzzy- or string matchers will struggle.",
    "crumbs": [
      "Example data"
    ]
  }
]